{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suitable-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Activation, Input, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adolescent-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(160, input_shape=input_shape, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adult-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(labels):\n",
    "    dic = {}\n",
    "    keys = np.unique(labels)\n",
    "    \n",
    "    for i in range(len(keys)):\n",
    "        dic[keys[i]] = i\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = dic[labels[i]]\n",
    "        \n",
    "    return to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "progressive-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = [\"01\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"15\", \"16\", \"18\", \"21\", \"22\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chronic-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_channels = 17\n",
    "number_of_clusters = [2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complete-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 60\n",
    "features_path = f\"/home/npe/seizure-prediction/Data/Interval-300-classes-length-{length}/Features/classification-1-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "understanding-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_classify = [['1', '5'],\n",
    "                       ['1', '5', '10'],\n",
    "                       ['1', '3', '5', '7' '10'],\n",
    "                       ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "approximate-melissa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2:\n",
      "(2590, 68)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 160)               11040     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                8050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 19,192\n",
      "Trainable params: 19,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.6913 - accuracy: 0.5476 - val_loss: 0.6476 - val_accuracy: 0.8462\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6664 - accuracy: 0.5503 - val_loss: 0.6365 - val_accuracy: 0.8462\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6441 - accuracy: 0.6669 - val_loss: 0.5848 - val_accuracy: 0.7692\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.6235 - accuracy: 0.7360 - val_loss: 0.6312 - val_accuracy: 0.5769\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.6082 - accuracy: 0.7032 - val_loss: 0.5557 - val_accuracy: 0.8846\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5863 - accuracy: 0.7473 - val_loss: 0.5238 - val_accuracy: 0.8462\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5637 - accuracy: 0.7718 - val_loss: 0.5056 - val_accuracy: 0.8077\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5486 - accuracy: 0.7613 - val_loss: 0.4914 - val_accuracy: 0.8077\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.5281 - accuracy: 0.8007 - val_loss: 0.4624 - val_accuracy: 0.8077\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5138 - accuracy: 0.7683 - val_loss: 0.4237 - val_accuracy: 0.9231\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4902 - accuracy: 0.7765 - val_loss: 0.4344 - val_accuracy: 0.8462\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.7980 - val_loss: 0.3852 - val_accuracy: 0.8077\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4611 - accuracy: 0.7828 - val_loss: 0.3908 - val_accuracy: 0.8462\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7925 - val_loss: 0.3992 - val_accuracy: 0.8462\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4396 - accuracy: 0.8093 - val_loss: 0.3502 - val_accuracy: 0.8077\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.7925 - val_loss: 0.4076 - val_accuracy: 0.8846\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.8081 - val_loss: 0.3521 - val_accuracy: 0.8462\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4175 - accuracy: 0.8151 - val_loss: 0.3315 - val_accuracy: 0.8462\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4144 - accuracy: 0.7976 - val_loss: 0.3866 - val_accuracy: 0.8846\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4133 - accuracy: 0.8163 - val_loss: 0.3001 - val_accuracy: 0.8077\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4273 - accuracy: 0.7913 - val_loss: 0.4485 - val_accuracy: 0.8462\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.8155 - val_loss: 0.2905 - val_accuracy: 0.8077\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.7890 - val_loss: 0.4727 - val_accuracy: 0.8462\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8206 - val_loss: 0.3069 - val_accuracy: 0.8462\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8128 - val_loss: 0.3649 - val_accuracy: 0.8846\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8089 - val_loss: 0.4481 - val_accuracy: 0.8462\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4595 - accuracy: 0.8120 - val_loss: 0.3207 - val_accuracy: 0.8462\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8112 - val_loss: 0.3209 - val_accuracy: 0.8462\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3952 - accuracy: 0.8124 - val_loss: 0.4065 - val_accuracy: 0.8462\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.8296 - val_loss: 0.3982 - val_accuracy: 0.8462\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3989 - accuracy: 0.8264 - val_loss: 0.3304 - val_accuracy: 0.8846\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.8136 - val_loss: 0.3415 - val_accuracy: 0.8846\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3851 - accuracy: 0.8194 - val_loss: 0.3824 - val_accuracy: 0.8462\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3893 - accuracy: 0.8241 - val_loss: 0.4003 - val_accuracy: 0.8462\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3967 - accuracy: 0.8264 - val_loss: 0.3408 - val_accuracy: 0.8846\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3861 - accuracy: 0.8202 - val_loss: 0.3740 - val_accuracy: 0.8846\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3857 - accuracy: 0.8280 - val_loss: 0.4193 - val_accuracy: 0.8462\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8303 - val_loss: 0.3243 - val_accuracy: 0.8846\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8163 - val_loss: 0.3696 - val_accuracy: 0.8846\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8257 - val_loss: 0.2958 - val_accuracy: 0.8462\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4259 - accuracy: 0.7984 - val_loss: 0.2983 - val_accuracy: 0.8462\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.8140 - val_loss: 0.3935 - val_accuracy: 0.8462\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.8292 - val_loss: 0.3221 - val_accuracy: 0.8846\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3862 - accuracy: 0.8179 - val_loss: 0.3697 - val_accuracy: 0.8846\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.8300 - val_loss: 0.3256 - val_accuracy: 0.8846\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8147 - val_loss: 0.3488 - val_accuracy: 0.8846\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.8249 - val_loss: 0.3857 - val_accuracy: 0.8462\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3798 - accuracy: 0.8264 - val_loss: 0.3732 - val_accuracy: 0.8462\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.8327 - val_loss: 0.3851 - val_accuracy: 0.8462\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3799 - accuracy: 0.8253 - val_loss: 0.3551 - val_accuracy: 0.8846\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8268 - val_loss: 0.3028 - val_accuracy: 0.8462\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8007 - val_loss: 0.3619 - val_accuracy: 0.8846\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3905 - accuracy: 0.8319 - val_loss: 0.4704 - val_accuracy: 0.8462\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3927 - accuracy: 0.8366 - val_loss: 0.2948 - val_accuracy: 0.8462\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8011 - val_loss: 0.5315 - val_accuracy: 0.8462\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5250 - accuracy: 0.7387 - val_loss: 0.2963 - val_accuracy: 0.8462\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.5659 - accuracy: 0.7520 - val_loss: 0.3423 - val_accuracy: 0.8077\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7832 - val_loss: 0.5974 - val_accuracy: 0.8077\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.8186 - val_loss: 0.3916 - val_accuracy: 0.8462\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.7917 - val_loss: 0.3420 - val_accuracy: 0.8846\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7863 - val_loss: 0.4123 - val_accuracy: 0.8462\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4309 - accuracy: 0.8339 - val_loss: 0.4639 - val_accuracy: 0.8462\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8108 - val_loss: 0.3305 - val_accuracy: 0.8462\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7769 - val_loss: 0.3377 - val_accuracy: 0.8462\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8218 - val_loss: 0.5157 - val_accuracy: 0.8462\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4363 - accuracy: 0.8374 - val_loss: 0.3651 - val_accuracy: 0.8846\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8054 - val_loss: 0.3065 - val_accuracy: 0.8077\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8186 - val_loss: 0.5159 - val_accuracy: 0.8462\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4120 - accuracy: 0.8374 - val_loss: 0.3214 - val_accuracy: 0.8462\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4306 - accuracy: 0.7945 - val_loss: 0.2947 - val_accuracy: 0.8462\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7988 - val_loss: 0.3941 - val_accuracy: 0.8462\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8311 - val_loss: 0.3565 - val_accuracy: 0.8846\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.7972 - val_loss: 0.2966 - val_accuracy: 0.8462\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.7968 - val_loss: 0.4244 - val_accuracy: 0.8462\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8397 - val_loss: 0.4753 - val_accuracy: 0.8462\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8362 - val_loss: 0.3425 - val_accuracy: 0.8846\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8194 - val_loss: 0.3454 - val_accuracy: 0.8846\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8253 - val_loss: 0.3678 - val_accuracy: 0.8846\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8225 - val_loss: 0.3122 - val_accuracy: 0.8462\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8085 - val_loss: 0.3407 - val_accuracy: 0.8846\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8339 - val_loss: 0.3846 - val_accuracy: 0.8462\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8101 - val_loss: 0.2887 - val_accuracy: 0.8077\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8124 - val_loss: 0.4533 - val_accuracy: 0.8462\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8378 - val_loss: 0.3916 - val_accuracy: 0.8462\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8253 - val_loss: 0.2892 - val_accuracy: 0.8077\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.7929 - val_loss: 0.3457 - val_accuracy: 0.8846\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8335 - val_loss: 0.5476 - val_accuracy: 0.8462\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8300 - val_loss: 0.3005 - val_accuracy: 0.8462\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8034 - val_loss: 0.3316 - val_accuracy: 0.8846\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8257 - val_loss: 0.4242 - val_accuracy: 0.8462\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8307 - val_loss: 0.3660 - val_accuracy: 0.8462\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.8323 - val_loss: 0.4461 - val_accuracy: 0.8462\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8389 - val_loss: 0.3529 - val_accuracy: 0.8846\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.7995 - val_loss: 0.2883 - val_accuracy: 0.8462\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.7933 - val_loss: 0.3997 - val_accuracy: 0.8462\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8413 - val_loss: 0.4896 - val_accuracy: 0.8462\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3914 - accuracy: 0.8300 - val_loss: 0.3404 - val_accuracy: 0.8846\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8296 - val_loss: 0.3837 - val_accuracy: 0.8462\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8229 - val_loss: 0.3228 - val_accuracy: 0.8462\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8288 - val_loss: 0.4273 - val_accuracy: 0.8462\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8331 - val_loss: 0.3801 - val_accuracy: 0.8462\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8300 - val_loss: 0.3794 - val_accuracy: 0.8462\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8311 - val_loss: 0.3904 - val_accuracy: 0.8462\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8311 - val_loss: 0.3620 - val_accuracy: 0.8462\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8284 - val_loss: 0.3447 - val_accuracy: 0.8846\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8218 - val_loss: 0.3186 - val_accuracy: 0.8462\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8233 - val_loss: 0.3671 - val_accuracy: 0.8462\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8303 - val_loss: 0.3925 - val_accuracy: 0.8462\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8311 - val_loss: 0.3335 - val_accuracy: 0.8846\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.2946 - val_accuracy: 0.8462\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8261 - val_loss: 0.4426 - val_accuracy: 0.8462\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8354 - val_loss: 0.3977 - val_accuracy: 0.8462\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8272 - val_loss: 0.2935 - val_accuracy: 0.8462\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8085 - val_loss: 0.3216 - val_accuracy: 0.8846\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8292 - val_loss: 0.3628 - val_accuracy: 0.8462\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8249 - val_loss: 0.3065 - val_accuracy: 0.8462\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8046 - val_loss: 0.3143 - val_accuracy: 0.8462\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8288 - val_loss: 0.4504 - val_accuracy: 0.8462\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8335 - val_loss: 0.3494 - val_accuracy: 0.8846\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8198 - val_loss: 0.3293 - val_accuracy: 0.8846\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8264 - val_loss: 0.4623 - val_accuracy: 0.8462\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.8307 - val_loss: 0.4158 - val_accuracy: 0.8462\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8210 - val_loss: 0.2844 - val_accuracy: 0.8077\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8077 - val_loss: 0.4441 - val_accuracy: 0.8462\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8436 - val_loss: 0.4315 - val_accuracy: 0.8462\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3772 - accuracy: 0.8276 - val_loss: 0.2887 - val_accuracy: 0.8077\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4232 - accuracy: 0.7984 - val_loss: 0.3660 - val_accuracy: 0.8462\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8405 - val_loss: 0.4989 - val_accuracy: 0.8462\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3900 - accuracy: 0.8284 - val_loss: 0.3115 - val_accuracy: 0.8462\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3832 - accuracy: 0.8233 - val_loss: 0.4783 - val_accuracy: 0.8462\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3973 - accuracy: 0.8413 - val_loss: 0.3737 - val_accuracy: 0.8462\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8222 - val_loss: 0.3125 - val_accuracy: 0.8462\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.8300 - val_loss: 0.4618 - val_accuracy: 0.8462\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8444 - val_loss: 0.3609 - val_accuracy: 0.8462\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4060 - accuracy: 0.8066 - val_loss: 0.2888 - val_accuracy: 0.8077\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8093 - val_loss: 0.3762 - val_accuracy: 0.8462\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.3759 - accuracy: 0.8331 - val_loss: 0.3942 - val_accuracy: 0.8462\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3745 - accuracy: 0.8280 - val_loss: 0.3416 - val_accuracy: 0.8846\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.8261 - val_loss: 0.3525 - val_accuracy: 0.8846\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3739 - accuracy: 0.8276 - val_loss: 0.3749 - val_accuracy: 0.8462\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.8350 - val_loss: 0.4274 - val_accuracy: 0.8462\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8354 - val_loss: 0.3536 - val_accuracy: 0.8462\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8245 - val_loss: 0.3547 - val_accuracy: 0.8462\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8374 - val_loss: 0.4918 - val_accuracy: 0.8462\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8362 - val_loss: 0.3171 - val_accuracy: 0.8846\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.8264 - val_loss: 0.4479 - val_accuracy: 0.8462\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8381 - val_loss: 0.4760 - val_accuracy: 0.8462\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.8381 - val_loss: 0.3082 - val_accuracy: 0.8462\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.8081 - val_loss: 0.3002 - val_accuracy: 0.8462\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8206 - val_loss: 0.4496 - val_accuracy: 0.8462\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8440 - val_loss: 0.4540 - val_accuracy: 0.8462\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8350 - val_loss: 0.3750 - val_accuracy: 0.8462\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.8280 - val_loss: 0.3219 - val_accuracy: 0.8846\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8198 - val_loss: 0.3747 - val_accuracy: 0.8462\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8374 - val_loss: 0.5591 - val_accuracy: 0.8077\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8389 - val_loss: 0.3483 - val_accuracy: 0.8846\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8112 - val_loss: 0.3086 - val_accuracy: 0.8462\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8210 - val_loss: 0.4300 - val_accuracy: 0.8462\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3920 - accuracy: 0.8417 - val_loss: 0.4232 - val_accuracy: 0.8462\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8307 - val_loss: 0.3686 - val_accuracy: 0.8462\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8339 - val_loss: 0.4157 - val_accuracy: 0.8462\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3737 - accuracy: 0.8342 - val_loss: 0.3170 - val_accuracy: 0.8462\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8081 - val_loss: 0.2985 - val_accuracy: 0.8462\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.8190 - val_loss: 0.4136 - val_accuracy: 0.8462\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8362 - val_loss: 0.3452 - val_accuracy: 0.8846\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8218 - val_loss: 0.3520 - val_accuracy: 0.8462\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8381 - val_loss: 0.4783 - val_accuracy: 0.8462\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.8342 - val_loss: 0.3218 - val_accuracy: 0.8846\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.8284 - val_loss: 0.4592 - val_accuracy: 0.8462\n",
      "Epoch 170/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8436 - val_loss: 0.3810 - val_accuracy: 0.8462\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8237 - val_loss: 0.2941 - val_accuracy: 0.8462\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8159 - val_loss: 0.3982 - val_accuracy: 0.8462\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8389 - val_loss: 0.4983 - val_accuracy: 0.8462\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.8397 - val_loss: 0.3149 - val_accuracy: 0.8846\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8198 - val_loss: 0.3276 - val_accuracy: 0.8846\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8323 - val_loss: 0.4833 - val_accuracy: 0.8462\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8393 - val_loss: 0.3603 - val_accuracy: 0.8462\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8268 - val_loss: 0.3175 - val_accuracy: 0.8846\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8241 - val_loss: 0.3831 - val_accuracy: 0.8462\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.8374 - val_loss: 0.3783 - val_accuracy: 0.8462\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8229 - val_loss: 0.3331 - val_accuracy: 0.8846\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8428 - val_loss: 0.5112 - val_accuracy: 0.8462\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8389 - val_loss: 0.3529 - val_accuracy: 0.8462\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3886 - accuracy: 0.8249 - val_loss: 0.3581 - val_accuracy: 0.8846\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3925 - accuracy: 0.8202 - val_loss: 0.3552 - val_accuracy: 0.8846\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8311 - val_loss: 0.4540 - val_accuracy: 0.8462\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8381 - val_loss: 0.4079 - val_accuracy: 0.8462\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.8319 - val_loss: 0.3341 - val_accuracy: 0.8846\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8257 - val_loss: 0.3801 - val_accuracy: 0.8462\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8292 - val_loss: 0.3819 - val_accuracy: 0.8462\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8378 - val_loss: 0.4815 - val_accuracy: 0.8462\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8452 - val_loss: 0.4402 - val_accuracy: 0.8462\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3766 - accuracy: 0.8319 - val_loss: 0.3175 - val_accuracy: 0.8462\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8229 - val_loss: 0.3897 - val_accuracy: 0.8462\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8378 - val_loss: 0.4189 - val_accuracy: 0.8462\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3739 - accuracy: 0.8315 - val_loss: 0.3868 - val_accuracy: 0.8462\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8428 - val_loss: 0.5232 - val_accuracy: 0.8462\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8436 - val_loss: 0.3335 - val_accuracy: 0.8846\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8233 - val_loss: 0.3052 - val_accuracy: 0.8462\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.8249 - val_loss: 0.4739 - val_accuracy: 0.8462\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8472\n",
      "0.8472222089767456\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5db7cc4c55b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;31m# Precision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mprec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0mprecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     \"\"\"\n\u001b[0;32m-> 1653\u001b[0;31m     p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1654\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                                                  \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1462\u001b[0m                                     pos_label)\n\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1272\u001b[0m                          str(average_options))\n\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1274\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "\n",
    "ws.append(['Patient', 'Accuracy(%)', 'Precision(%)', 'Recall(%)', 'Specificity(%)', 'FPR(/h)'])\n",
    "\n",
    "for ctc in classes_to_classify:\n",
    "    for cluster in number_of_clusters:\n",
    "        all_accs, all_precs, all_sens, all_specs, all_fprs = [], [], [], [], []\n",
    "\n",
    "        cluster_path = f\"{features_path}/{cluster}-clusters\"\n",
    "        classes = os.listdir(cluster_path)\n",
    "        print(f\"Cluster {cluster}:\")\n",
    "\n",
    "        for pt in pts:\n",
    "            x, y, x_train, x_test, y_train, y_test = [], [], [], [], [], []\n",
    "\n",
    "            for _class in classes:\n",
    "                if _class[6:] in ctc:\n",
    "                    class_path = f\"{cluster_path}/{_class}\"\n",
    "                    class_data = os.listdir(class_path)\n",
    "\n",
    "                    for data in class_data:\n",
    "                        if data[2:4] == pt:\n",
    "                            try:\n",
    "                                x.append(np.load(f\"{class_path}/{data}\"))\n",
    "                                y.append(data.split('-')[1][5:])\n",
    "                            except:\n",
    "                                print('*****')\n",
    "\n",
    "            x, y = shuffle(x, y)             \n",
    "\n",
    "            # Test split\n",
    "            kf = KFold(n_splits=10)\n",
    "\n",
    "            accs, precs, sens, specs, fprs = [], [], [], [], []\n",
    "\n",
    "            for train_index, test_index in kf.split(x):\n",
    "    #             print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "                x_train, x_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "                for i in range(len(x)):\n",
    "                    if i in test_index:\n",
    "                        x_test.append(x[i]/1279)\n",
    "                        y_test.append(y[i])\n",
    "\n",
    "                    else:\n",
    "                        x_train.append(x[i]/1279)\n",
    "                        y_train.append(y[i])\n",
    "\n",
    "                x_train, x_test = np.array(x_train), np.array(x_test)\n",
    "                y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "\n",
    "                y_train, y_test = one_hot_encoding(y_train), one_hot_encoding(y_test)\n",
    "\n",
    "                reshape_to = x_train.shape[1] * x_train.shape[2]\n",
    "                x_train = np.array([i.reshape((reshape_to)) for i in x_train])\n",
    "\n",
    "                reshape_to = x_test.shape[1] * x_test.shape[2]\n",
    "                x_test = np.array([i.reshape((reshape_to)) for i in x_test])\n",
    "                \n",
    "                print(x_train.shape)\n",
    "                \n",
    "                # MLP\n",
    "                model = build_model((x_train.shape[1],), \n",
    "                                    len(ctc))\n",
    "                \n",
    "                hist = model.fit(x_train, y_train, batch_size = 512, epochs = 200, verbose = 1, validation_split=0.01)\n",
    "                \n",
    "                # Accuracy\n",
    "                loss , acc = model.evaluate(x_test, y_test, verbose=1)\n",
    "                accs.append(round(acc*100, 2))\n",
    "                print(acc)\n",
    "                \n",
    "                plt.plot(hist.history['accuracy'])\n",
    "                plt.plot(hist.history['val_accuracy'])\n",
    "                plt.legend(['training', 'validation'], loc = 'upper left')\n",
    "                plt.show()\n",
    "\n",
    "                y_pred = model.predict(x_test)\n",
    "\n",
    "                # Precision\n",
    "                prec = precision_score(y_test, y_pred, average='macro')\n",
    "                precs.append(round(prec*100, 2))\n",
    "\n",
    "                # Recall (SEN)\n",
    "                rec = recall_score(y_test, y_pred, average='macro')\n",
    "                sens.append(round(rec*100, 2))\n",
    "\n",
    "                # SPEC\n",
    "                spec = SPEC(y_test, y_pred)\n",
    "                specs.append(spec)\n",
    "\n",
    "                # FPR\n",
    "                fpr = FPR(y_test, y_pred)\n",
    "                fprs.append(fpr)\n",
    "\n",
    "            # Calculating the averages\n",
    "            pt_acc = round(np.mean(accs), 2)\n",
    "            all_accs.append(pt_acc)\n",
    "\n",
    "            pt_prec = round(np.mean(precs), 2)\n",
    "            all_precs.append(pt_prec)\n",
    "\n",
    "            pt_rec = round(np.mean(sens), 2)\n",
    "            all_sens.append(pt_rec)\n",
    "\n",
    "            pt_spec = round(np.mean(specs), 2)\n",
    "            all_specs.append(pt_spec)\n",
    "\n",
    "            pt_fpr = round(np.mean(fprs), 3)\n",
    "            all_fprs.append(pt_fpr)\n",
    "\n",
    "\n",
    "            print(f\"Pt-{pt}:\")\n",
    "            print(f\"accuracy: {pt_acc}\\nprecision: {pt_prec}\\nrecall: {pt_rec}\\nSPEC: {pt_spec}\\nFPR: {pt_fpr}\\n\")\n",
    "\n",
    "            row = [f\"Pt-{pt}\", pt_acc, pt_prec, pt_rec, pt_spec, pt_fpr]\n",
    "\n",
    "            ws.append(row)\n",
    "\n",
    "        ws.append(['Average', round(np.mean(all_accs), 2), round(np.mean(all_precs), 2), round(np.mean(all_sens), 2), round(np.mean(all_specs), 2), round(np.mean(all_fprs), 3)])\n",
    "        ws.append(['*'])\n",
    "\n",
    "    wb.save(f\"Results/{length}/classes_1_2_3_4_5_6_7_8_9_10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-cartridge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_classify = [['1', '10'], \n",
    "                       ['1', '5', '10'], \n",
    "                       ['1', '3', '5', '7', '10'], \n",
    "                       ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unknown-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'class-1'[5:] in classes_to_classify[0]:\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "twelve-wedding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'class-1'[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "transparent-salad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['1', '3', '5', '3', '3', '1']\n",
    "one_hot_encoding(np.array(labels)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eastern-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load('/home/npe/seizure-prediction/Data/Interval-300-classes-length-60/Features/3-clusters/class-1/pt01-class1-0-60min.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "annual-colorado",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 20)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dental-recorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape: (94556,)\n",
      "xr.shape:(94556, 1)\n",
      "y.shape: (94556, 2557)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(0,2557,94556)\n",
    "y = np.eye((2557))[np.random.randint(0,2557,94556)]\n",
    "xr = x.reshape((-1,1))\n",
    "\n",
    "\n",
    "print(\"x.shape: {}\\nxr.shape:{}\\ny.shape: {}\".format(x.shape, xr.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-trail",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
